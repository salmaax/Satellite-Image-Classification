{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EuroSAT — Step 1: Data Preprocessing & Augmentation\n",
    "# Objective: \n",
    "# load EuroSAT,\n",
    "# inspect class balance,\n",
    "# implement model-aware preprocessing,\n",
    "# apply augmentation, \n",
    "# demonstrate augmentation worked,\n",
    "# and provide two imbalance-handling strategies (class weights and targeted oversampling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "204c9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bfadb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e55d35ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== EuroSAT Dataset Info =====\n",
      "Number of examples: 27000\n",
      "Number of classes: 10\n",
      "Class names: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "Image shape: (64, 64, 3)\n",
      "Image dtype: <dtype: 'uint8'>\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('eurosat', with_info=True, as_supervised=True)\n",
    "full_ds = dataset['train']\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes\n",
    "class_names = info.features['label'].names\n",
    "image_shape = info.features['image'].shape\n",
    "image_dtype = info.features['image'].tf_dtype\n",
    "\n",
    "print(\"===== EuroSAT Dataset Info =====\")\n",
    "print(f\"Number of examples: {num_examples}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Image shape: {image_shape}\")\n",
    "print(f\"Image dtype: {image_dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4df5bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and normalize\n",
    "\n",
    "def resize_and_rescale(image, label, target=224):\n",
    "    image = tf.image.resize(image, [target, target])    #resize images from 64×64 to 224×224\n",
    "    image = tf.cast(image, tf.float32) / 255.0     #convert pixel type\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "620be19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = full_ds.map(resize_and_rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64f60a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 22950, Val examples: 4050\n"
     ]
    }
   ],
   "source": [
    "num_examples = tf.data.experimental.cardinality(full_ds).numpy()\n",
    "train_size = int(0.85 * num_examples)\n",
    "\n",
    "# (85% train / 15% val)\n",
    "train_ds = full_ds.take(train_size)\n",
    "val_ds = full_ds.skip(train_size)\n",
    "\n",
    "# how many examples in each split\n",
    "train_count = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "val_count   = tf.data.experimental.cardinality(val_ds).numpy()\n",
    "print(f\"Train examples: {train_count}, Val examples: {val_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7eeb411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class counts (train):\n",
      "  class 0: 2563 images\n",
      "  class 1: 2564 images\n",
      "  class 2: 2527 images\n",
      "  class 3: 2121 images\n",
      "  class 4: 2128 images\n",
      "  class 5: 1699 images\n",
      "  class 6: 2107 images\n",
      "  class 7: 2546 images\n",
      "  class 8: 2147 images\n",
      "  class 9: 2548 images\n"
     ]
    }
   ],
   "source": [
    "# Inspect class counts (detect imbalance)\n",
    "counts = collections.Counter() #dictionary-like object that counts occurrences of items\n",
    "y_train_list = []\n",
    "\n",
    "\n",
    "for _, lbl in tfds.as_numpy(train_ds):\n",
    "    counts[int(lbl)] += 1\n",
    "    y_train_list.append(int(lbl))\n",
    "\n",
    "print(\"Per-class counts (train):\")\n",
    "for cls in sorted(counts.keys()):\n",
    "    print(f\"  class {cls}: {counts[cls]} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0cf1606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no class imbalance, so we'll apply light augmentation just to\n",
    "# improve model training and generalization and reduce overfitting\n",
    "\n",
    "#minimal light augmentation\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "620f8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply augmentation to the training dataset only\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True),y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
